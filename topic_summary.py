import json
from llm_model_pull import OllamaRunner
from topic_crawler import NPRCrawler

class DebateLLMProcessor:
    """
    í† ë¡  ì£¼ì œì— ëŒ€í•œ ì •ë³´ë¥¼ í¬ë¡¤ë§í•˜ê³  ìš”ì•½ ë° ì°¬ë°˜ ì˜ê²¬ì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤.
    """

    def __init__(self, model_name="mistral"):
        """
        Ollama ê¸°ë°˜ì˜ LLM ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.

        :param model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: "mistral")
        """
        self.model_name = model_name
        self.llm = OllamaRunner()  # OllamaRunner ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.llm.set_model(model_name)  # ëª¨ë¸ ì„¤ì •

    def generate_response(self, prompt):
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±.

        :param prompt: LLMì—ê²Œ ë³´ë‚¼ ìš”ì²­ í…ìŠ¤íŠ¸
        :return: LLMì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        return self.llm.generate_text(prompt)

    def summarize_articles(self, topic, articles):
        """
        í¬ë¡¤ë§í•œ ê¸°ì‚¬ ë‚´ìš©ì„ ìš”ì•½.

        :param topic: í† ë¡  ì£¼ì œ
        :param articles: ê¸°ì‚¬ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸
        :return: ìš”ì•½ëœ ë‚´ìš©
        """
        if not articles:
            return "âŒ ê¸°ì‚¬ ìš”ì•½ ì‹¤íŒ¨: í¬ë¡¤ë§ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."

        combined_text = " ".join(articles[:3])  # ìƒìœ„ 3ê°œ ê¸°ì‚¬ ë‚´ìš©ì„ ê²°í•©
        prompt = f"Summarize the following text about {topic} in 300 words:\n{combined_text}"
        return self.generate_response(prompt)

    def generate_pros_cons(self, topic, summary):
        """
        í† ë¡  ì£¼ì œì— ëŒ€í•œ ì°¬ì„± ë° ë°˜ëŒ€ ì˜ê²¬ì„ ìƒì„±.

        :param topic: í† ë¡  ì£¼ì œ
        :param summary: ìš”ì•½ëœ ê¸°ì‚¬ ë‚´ìš©
        :return: (ì°¬ì„± ì˜ê²¬, ë°˜ëŒ€ ì˜ê²¬)
        """
        pro_prompt = f"Provide a pro argument for {topic} based on the following summary:\n{summary}"
        con_prompt = f"Provide a con argument for {topic} based on the following summary:\n{summary}"
        
        pro_argument = self.generate_response(pro_prompt)
        con_argument = self.generate_response(con_prompt)

        return pro_argument, con_argument

    def process_and_save(self, topic, articles):
        """
        í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ìš”ì•½ ë° ì°¬ë°˜ ì˜ê²¬ ìƒì„± í›„ JSON íŒŒì¼ë¡œ ì €ì¥.

        :param topic: í† ë¡  ì£¼ì œ
        :param articles: ê¸°ì‚¬ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        # ğŸ”¹ ê¸°ì‚¬ ë°ì´í„° êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹… ìš©ë„)
        print(f"\nğŸ” í¬ë¡¤ë§ëœ ê¸°ì‚¬ ë°ì´í„° êµ¬ì¡° í™•ì¸: {articles}\n")

        summary = self.summarize_articles(topic, articles)
        pros, cons = self.generate_pros_cons(topic, summary)

        debate_data = {
            "topic": topic,
            "summary": summary,
            "pros": pros,
            "cons": cons
        }

        # JSON íŒŒì¼ë¡œ ì €ì¥
        file_name = f"debate_{topic.replace(' ', '_')}.json"
        with open(file_name, "w", encoding="utf-8") as f:
            json.dump(debate_data, f, indent=4, ensure_ascii=False)

        print(f"âœ… í† ë¡  ë°ì´í„°ê°€ '{file_name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def run_pipeline(self, topic):
        """
        í† ë¡  ì£¼ì œì— ëŒ€í•œ í¬ë¡¤ë§ â†’ ìš”ì•½ â†’ ì°¬ë°˜ ì˜ê²¬ ìƒì„± â†’ ì €ì¥ê¹Œì§€ ìˆ˜í–‰.

        :param topic: í† ë¡  ì£¼ì œ
        """
        print(f"ğŸ” '{topic}' ê´€ë ¨ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘...")
        
        # ğŸ”¹ NPR ê¸°ì‚¬ í¬ë¡¤ë§
        crawler = NPRCrawler(headless=True)
        articles = crawler.get_top_articles(topic)
        crawler.close()

        if not articles:
            print("âŒ ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ğŸ”¹ ê¸°ì‚¬ ë°ì´í„° êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹… ìš©ë„)
        print(f"\nâœ… í¬ë¡¤ë§ëœ ê¸°ì‚¬ ê°œìˆ˜: {len(articles)}")
        for idx, article in enumerate(articles):
            print(f"{idx+1}. ì œëª©: {article.get('title', 'âŒ ì œëª© ì—†ìŒ')}")
            print(f"   ë³¸ë¬¸ ê¸¸ì´: {len(article.get('content', ''))}ì\n")

        # ğŸ”¹ ê¸°ì‚¬ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ë¹„ì–´ìˆëŠ” ê¸°ì‚¬ ì œê±°)
        articles_text = [article["content"] for article in articles if article["content"].strip()]

        # ğŸ”¹ ê¸°ì‚¬ ë³¸ë¬¸ì´ ëª¨ë‘ ë¹„ì–´ìˆì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
        if not articles_text:
            print("âŒ ëª¨ë“  ê¸°ì‚¬ ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return

        # ğŸ”¹ ìš”ì•½ ë° ì°¬ë°˜ ì˜ê²¬ ìƒì„± í›„ ì €ì¥
        self.process_and_save(topic, articles_text)
